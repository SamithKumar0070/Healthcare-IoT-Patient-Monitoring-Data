# -*- coding: utf-8 -*-
"""Healthcare IoT Patient Monitoring .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YLt6HdLeIRDJG8YVAKntUc_swmjaCd-A
"""

from google.colab import files
uploaded = files.upload()

"""Step 1-Uplaoding the file from local computer and letting it read as well in next steps as you see below:-"""

import pandas as pd
df = pd.read_csv('healthcare_iot_target_dataset.csv')

"""Step 2- Loading the Dataset and exploring the set as well ."""

import pandas as pd

# Load dataset
df = pd.read_csv("healthcare_iot_target_dataset.csv")

# Preview first few rows
print(df.head())

# Dataset info
print(df.info())

# Basic statistics
print(df.describe())

"""Here from the Data after Understanding from the dataset, we have columns like:

Patient_ID

Timestamp

Sensor_Type (Temperature, Blood Pressure, Heart Rate, Battery)

Temperature (¬∞C), Systolic_BP, Diastolic_BP, Heart_Rate, Battery Level

Target_Health_Status ‚Üí Label we can predict (Healthy / Unhealthy)

Some "Target_Blood_Pressure" & "Target_Heart_Rate" ‚Äî could be doctor‚Äôs recommended values.

We‚Äôll treat Target_Health_Status as the prediction target.

Step 3 ‚Äì Data Cleaning
Convert Timestamp to datetime

Handle possible missing values

Remove duplicates

Ensure numeric columns are correct
"""

# Convert time
df['Timestamp'] = pd.to_datetime(df['Timestamp'])

# Check missing values
print(df.isnull().sum())

# Drop duplicates if any
df = df.drop_duplicates()

"""Step 4 ‚Äì Exploratory Data Analysis (EDA)
Example: Heart Rate vs Health Status
"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x='Target_Health_Status', y='Heart_Rate (bpm)', data=df)
plt.title("Heart Rate Distribution by Health Status")
plt.show()

"""Now lets expleore EDA for
1. Correlation Heatmap of Vitals
The correlation between vital signs (Temperature, Systolic BP, Diastolic BP, Heart Rate) shows:

Strong positive correlation between Systolic and Diastolic Blood Pressure (~0.75).

Mild positive correlations among other vitals, such as between Heart Rate and Temperature.
This helps understand how these vitals relate to each other in patient monitoring.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("healthcare_iot_target_dataset.csv")

# Convert Timestamp to datetime
df['Timestamp'] = pd.to_datetime(df['Timestamp'])

# Select vital sign columns for analysis
vitals = ['Temperature (¬∞C)', 'Systolic_BP (mmHg)', 'Diastolic_BP (mmHg)', 'Heart_Rate (bpm)']

# 1. Correlation Heatmap of Vitals
plt.figure(figsize=(8, 6))
corr = df[vitals].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap of Vitals')
plt.show()

# 2. Time-Series Plots for a Given Patient (e.g., Patient ID 8270)
patient_id = 8270
patient_data = df[df['Patient_ID'] == patient_id]
plt.figure(figsize=(12, 8))
for vital in vitals:
    plt.plot(patient_data['Timestamp'], patient_data[vital], label=vital)
plt.xlabel('Timestamp')
plt.ylabel('Vital Sign Measurement')
plt.title(f'Time-Series of Vitals for Patient {patient_id}')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 3. Average Vitals for Healthy vs Unhealthy Patients
avg_vitals = df.groupby('Target_Health_Status')[vitals].mean().reset_index()
print("Average vitals grouped by Health Status:")
print(avg_vitals)

"""Summary of Results:
The correlation heatmap reveals relationships between temperature, systolic and diastolic blood pressure, and heart rate. For example, systolic and diastolic pressures have a strong positive correlation, which is expected physiologically.

Step 5 ‚Äì Feature Selection & Encoding
Drop non-essential IDs

Convert categorical labels to numeric
"""

from sklearn.preprocessing import LabelEncoder

df_model = df.copy()
df_model = df_model.drop(columns=['Patient_ID', 'Sensor_ID', 'Timestamp', 'Sensor_Type'])
le = LabelEncoder()
df_model['Target_Health_Status'] = le.fit_transform(df_model['Target_Health_Status'])  # Healthy=0, Unhealthy=1

"""Step 6 ‚Äì Train-Test Split & Scaling"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = df_model.drop(columns=['Target_Health_Status'])
y = df_model['Target_Health_Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Step 7 ‚Äì Machine Learning Model
We start with Random Forest for classification.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')
plt.show()

"""The image you provided is a confusion matrix visualization, which is commonly used to evaluate the performance of a classification model in machine learning. Here‚Äôs what it means:

The rows represent the "True" labels (actual health status), and the columns represent the "Predicted" labels (model's output), though axis labels are not shown here.

Each box contains a count representing the number of times a particular true class was predicted as a specific class.

Reading your matrix:

              Predicted 0	          Predicted 1
Actual 0	         10	                   8
Actual 1	          3	                   19

10: True Negatives (actual 0, predicted 0)

19: True Positives (actual 1, predicted 1)

8: False Positives (actual 0, predicted 1)

3: False Negatives (actual 1, predicted 0)

Interpretation:

Your model correctly classified 10 cases as class 0 and 19 cases as class 1.

It misclassified 8 cases as class 1 that were actually class 0 (false positives).

It misclassified 3 cases as class 0 that were actually class 1 (false negatives).

This matrix helps you assess:

The accuracy of your model (how often it gets things right).

Which types of errors your model makes more often (false positives vs. false negatives).

The trade-off between sensitivity (recall for class 1), specificity (recall for class 0), and overall performance.
"""

import pandas as pd

# Assuming you have a trained model named 'model'
# and a list of feature names used for training:
# feature_names = ['Temperature (¬∞C)', 'Systolic_BP (mmHg)', 'Diastolic_BP (mmHg)', 'Heart_Rate (bpm)', 'Battery Level (%)']
feature_names = ['Temperature (¬∞C)', 'Systolic_BP (mmHg)', 'Diastolic_BP (mmHg)', 'Heart_Rate (bpm)', 'Device_Battery_Level (%)', 'Target_Blood_Pressure', 'Target_Heart_Rate', 'Battery_Level (%)']


# Get feature importances from the model
importances = model.feature_importances_

# Create a DataFrame to display feature importance clearly
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

# Sort by importance descending
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)

print(feature_importance_df)

"""This means that, according to your trained Random Forest model:

Heart Rate (bpm), Device Battery Level (%), Battery Level (%), and Temperature (¬∞C) are the most important features for predicting the target health status.
Target Blood Pressure, Diastolic BP, Systolic BP, and Target Heart Rate are less important features in this particular model.
This insight is valuable because it tells you which sensor readings and device metrics are most predictive of the health status.
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ---------------------------
# LOAD DATA
# ---------------------------
@st.cache_data
def load_data():
    df = pd.read_csv("healthcare_iot_target_dataset.csv")
    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    return df

df = load_data()

st.title("üè• Healthcare IoT Patient Monitoring Dashboard")

# ---------------------------
# TRAIN MODEL
# ---------------------------
features = ['Temperature (¬∞C)', 'Systolic_BP (mmHg)', 'Diastolic_BP (mmHg)',
            'Heart_Rate (bpm)', 'Device_Battery_Level (%)']

le = LabelEncoder()
df['Target_Health_Status'] = le.fit_transform(df['Target_Health_Status'])  # Healthy=0, Unhealthy=1

X = df[features]
y = df['Target_Health_Status']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

st.write(f"‚úÖ **Model Accuracy:** {accuracy:.2%}")

# ---------------------------
# PATIENT SELECTION
# ---------------------------
patient_id = st.selectbox("Select Patient ID", df['Patient_ID'].unique())
patient_data = df[df['Patient_ID'] == patient_id]

# ---------------------------
# VITALS OVER TIME
# ---------------------------
st.subheader(f"üìà Vitals Over Time - Patient {patient_id}")
st.line_chart(patient_data.set_index('Timestamp')[['Temperature (¬∞C)', 'Systolic_BP (mmHg)',
                                                   'Diastolic_BP (mmHg)', 'Heart_Rate (bpm)']])

# ---------------------------
# HEALTH PREDICTION FOR PATIENT
# ---------------------------
latest = patient_data[features].iloc[-1]
latest_scaled = scaler.transform([latest])
prediction = model.predict(latest_scaled)[0]
pred_label = le.inverse_transform([prediction])[0]

if pred_label == "Unhealthy":
    st.error(f"üö® Prediction: {pred_label}")
else:
    st.success(f"‚úÖ Prediction: {pred_label}")

# ---------------------------
# AVERAGE VITALS BY STATUS
# ---------------------------
st.subheader("üìä Average Vitals by Health Status")
avg_vitals = df.copy()
avg_vitals['Health Status'] = le.inverse_transform(avg_vitals['Target_Health_Status'])
avg_table = avg_vitals.groupby('Health Status')[features].mean()
st.dataframe(avg_table)

# ---------------------------
# CORRELATION HEATMAP
# ---------------------------
st.subheader("üîó Correlation Heatmap of Vitals")
fig, ax = plt.subplots()
sns.heatmap(df[features].corr(), annot=True, cmap='coolwarm', fmt='.2f', ax=ax)
st.pyplot(fig)

# ---------------------------
# FEATURE IMPORTANCE
# ---------------------------
st.subheader("üåü Feature Importance (Model)")
importances = pd.DataFrame({
    'Feature': features,
    'Importance': model.feature_importances_
}).sort_values(by="Importance", ascending=False)

fig2, ax2 = plt.subplots()
sns.barplot(x='Importance', y='Feature', data=importances, palette='viridis', ax=ax2)
st.pyplot(fig2)

"""The two images you shared represent key stages of a machine learning project for healthcare IoT patient monitoring:

1. Correlation Heatmap of Features
The first image is a correlation heatmap. Here‚Äôs what it means:

Purpose: Shows how much each pair of features (vital signs and device battery level) are linearly related.

Interpretation:

Bright red boxes (values close to 1.00) show a strong positive correlation.

Example: Systolic BP and Diastolic BP have a high correlation (0.91), which is expected physiologically.

Blue boxes (values close to 0 or negative) represent weak or negative/no correlation.

Example: Device Battery Level has almost no correlation with other health features.

Each box contains the correlation coefficient, ranging from -1 (perfect negative) to +1 (perfect positive).

How to use:\\
This helps us understand which features are related, which can help with feature selection for your model, and provides insight into the physiology behind the data.

2. Feature Importance Bar Chart

The second image is a feature importance chart from your Random Forest model:

Purpose: Shows which input features (from patient sensors) had the greatest effect on predicting health status.

Interpretation:

The longer the bar, the higher the importance of that feature for the model‚Äôs decisions.

Heart Rate was the most important predictor.

Device Battery Level and Temperature also played significant roles.

Blood Pressure values (Systolic and Diastolic) were less important for this model setup.

How to use:
With this chart, we can explain to others (e.g., recruiters, teammates) which data the model relies on most to make its health predictions. It also informs you where to focus attention for future feature engineering or additional data collection.

Summary
The correlation heatmap visualizes how health-related features (and device status) in your dataset are related to each other.

The feature importance chart tells you which features matter most for classifying whether a patient is healthy or unhealthy in your AI model.

Together, these visuals provide both data understanding (EDA) and interpretability for your machine learning model‚Äîessential components of an end-to-end data science project.


"""